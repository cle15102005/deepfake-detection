import os
import numpy as np
import pandas as pd
import tensorflow as tf
from datetime import datetime

# Import utils
# Äáº£m báº£o báº¡n Ä‘ang Ä‘á»ƒ file nÃ y cÃ¹ng cáº¥p vá»›i thÆ° má»¥c utils
from utils import data_loader, preprocessing, main_eval, save

# ==========================================
# âš™ï¸ Cáº¤U HÃŒNH (Báº N Cáº¦N Sá»¬A 2 DÃ’NG NÃ€Y)
# ==========================================

# 1. ğŸ‘‡ DÃ¡n Ä‘Æ°á»ng dáº«n file model .keras cá»§a báº¡n vÃ o Ä‘Ã¢y
# VÃ­ dá»¥: "save/model/efficientnetb0_ffnormal_20251230_155300.keras"
MODEL_PATH_TO_LOAD = "save/model/TÃŠN_FILE_MODEL_Cá»¦A_Báº N.keras" 

# 2. ğŸ‘‡ DÃ¡n Ä‘Æ°á»ng dáº«n file history .npy cá»§a báº¡n vÃ o Ä‘Ã¢y
# VÃ­ dá»¥: "save/history/efficientnetb0_ffnormal_20251230_155300.npy"
HISTORY_PATH_TO_LOAD = "save/history/TÃŠN_FILE_HISTORY_Cá»¦A_Báº N.npy"

# ------------------------------------------
# CÃC THÃ”NG Sá» KHÃC (GIá»® NGUYÃŠN NHÆ¯ LÃšC TRAIN)
# ------------------------------------------
MODEL_NAME   = "efficientnetb0" 
DATA_DIR     = "/mnt/d/PROJECT/virtual_env/DL/Project/FINAL_DATASET/Normal_Dataset/" 
DATASET_NAME = 'ffnormal'
BATCH_SIZE   = 32
IMAGE_SIZE   = (224, 224)
DROPOUT_RATE = 0.2  # 0.5 náº¿u lÃ  mesonet
LEARNING_RATE = 0.001 

# Setup Ä‘Æ°á»ng dáº«n save (Tá»± Ä‘á»™ng táº¡o tÃªn file má»›i cÃ³ Ä‘uÃ´i _RESUME)
SAVE_DIR = "save"
current_time = datetime.now().strftime("%Y%m%d_%H%M%S") 
file_dir     = f"{MODEL_NAME}_{DATASET_NAME}_{current_time}_RESUME"

# Táº¡o folder output náº¿u chÆ°a cÃ³
for folder in ['plot', 'test']:
    os.makedirs(os.path.join(SAVE_DIR, folder), exist_ok=True)

# ==========================================
# 1. LOAD Láº I Dá»® LIá»†U & MODEL
# ==========================================
print("\n" + "="*40)
print(" 1. LOAD DATA & MODEL")
print("="*40)

print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»«: {DATA_DIR}")
train_df, val_df, test_df = data_loader.load_datasets(DATA_DIR)

# Gá»™p DataFrame Ä‘á»ƒ tÃ­nh thá»‘ng kÃª cho hÃ m save_metrics
df = pd.concat([train_df, val_df, test_df])

print("âš™ï¸ Äang xá»­ lÃ½ dá»¯ liá»‡u (Preprocessing)...")
# Chá»‰ cáº§n táº¡o test_ds Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
# LÆ°u Ã½: train_ds vÃ  val_ds cÃ³ thá»ƒ bá» qua Ä‘á»ƒ tiáº¿t kiá»‡m RAM náº¿u khÃ´ng cáº§n dÃ¹ng láº¡i
_, _, test_ds = preprocessing.make_data(train_df, val_df, test_df, BATCH_SIZE, MODEL_NAME)

print(f"ğŸ§  Äang load model tá»«: {MODEL_PATH_TO_LOAD}")
try:
    model = tf.keras.models.load_model(MODEL_PATH_TO_LOAD)
    print("âœ… Load model thÃ nh cÃ´ng!")
except Exception as e:
    print(f"âŒ Lá»—i khi load model: {e}")
    print("ğŸ‘‰ HÃ£y kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n trong biáº¿n MODEL_PATH_TO_LOAD")
    exit()

# ==========================================
# 2. Xá»¬ LÃ HISTORY (Lá»ŠCH Sá»¬ HUáº¤N LUYá»†N)
# ==========================================
print("\n" + "="*40)
print(" 2. CHECKING TRAINING HISTORY")
print("="*40)

history = {}

# Thá»­ load file history tháº­t
if HISTORY_PATH_TO_LOAD and os.path.exists(HISTORY_PATH_TO_LOAD):
    print(f"ğŸ“ˆ TÃ¬m tháº¥y file history: {HISTORY_PATH_TO_LOAD}")
    try:
        history = np.load(HISTORY_PATH_TO_LOAD, allow_pickle=True).item()
        print("âœ… Load history thÃ nh cÃ´ng. Äang váº½ láº¡i biá»ƒu Ä‘á»“ Training...")
        
        # Váº½ láº¡i biá»ƒu Ä‘á»“ Loss/AUC/Accuracy
        main_eval.plot_history(history, f"{SAVE_DIR}/plot", file_dir)
    except Exception as e:
        print(f"âš ï¸ File history bá»‹ lá»—i hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c: {e}")
        print("â¡ï¸ Sáº½ sá»­ dá»¥ng history rá»—ng (dummy) Ä‘á»ƒ cháº¡y tiáº¿p.")
else:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y Ä‘Æ°á»ng dáº«n file history.")
    print("â¡ï¸ Sáº½ sá»­ dá»¥ng history rá»—ng (dummy) Ä‘á»ƒ cháº¡y tiáº¿p.")

# Äáº£m báº£o history cÃ³ cáº¥u trÃºc Ä‘Ãºng Ä‘á»ƒ hÃ m save khÃ´ng bá»‹ lá»—i
required_keys = ['loss', 'accuracy', 'val_loss', 'val_accuracy', 'auc', 'val_auc']
for key in required_keys:
    if key not in history:
        history[key] = [] 

# ==========================================
# 3. CHáº Y ÄÃNH GIÃ (TEST EVALUATE)
# ==========================================
print("\n" + "="*40)
print(" 3. RUNNING EVALUATION ON TEST SET")
print("="*40)

# Gá»i hÃ m test_evaluate (PhiÃªn báº£n má»›i tráº£ vá» 11 giÃ¡ trá»‹)
results, tn, fp, fn, tp, fpr, fnr, f1_score, y_true, y_pred, y_pred_probs = main_eval.test_evaluate(
    model, test_ds, f"{SAVE_DIR}/plot", file_dir, f"{SAVE_DIR}/test"
)

# ==========================================
# 4. LÆ¯U Káº¾T QUáº¢ (SAVE METRICS & PREDICTIONS)
# ==========================================
print("\n" + "="*40)
print(" 4. SAVING RESULTS")
print("="*40)

print("ğŸ’¾ Äang lÆ°u file metrics (JSON)...")
save.save_metrics(
    MODEL_NAME, DATASET_NAME, current_time, 
    results, f1_score, tn, fp, fn, tp, fpr, fnr, 
    history, BATCH_SIZE, LEARNING_RATE, IMAGE_SIZE, DROPOUT_RATE, 
    df, train_df, val_df, test_df, 
    f"{SAVE_DIR}/test", file_dir
)

print("ğŸ’¾ Äang lÆ°u file dá»± Ä‘oÃ¡n (NPZ)...")
save.save_pred(
    f"{SAVE_DIR}/test", file_dir, f"{SAVE_DIR}/plot", 
    y_true, y_pred, y_pred_probs, results
)

print("\nğŸ‰ HOÃ€N Táº¤T! ÄÃ£ cháº¡y xong toÃ n bá»™ pháº§n Ä‘Ã¡nh giÃ¡.")
print(f"ğŸ‘‰ Kiá»ƒm tra káº¿t quáº£ táº¡i thÆ° má»¥c: {SAVE_DIR}/test/ vÃ  {SAVE_DIR}/plot/")